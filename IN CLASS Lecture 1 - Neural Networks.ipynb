{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGKAZlCh02cl"
   },
   "source": [
    "# Introduction to Neural Networking in Keras\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/coding-dojo-data-science/week-11-lecture-2-tuning-deep-learning-models/blob/main/Code-along%20Tuning%20Neural%20Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OStduN-207_9"
   },
   "source": [
    "We will use the version of Keras that comes in the Tensorflow package, as it has the most up to date tools.\n",
    "\n",
    "Keras works as weapper for deep learning model to be used as classification or regression estimators in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.219225Z",
     "start_time": "2023-02-08T02:15:00.211839Z"
    },
    "executionInfo": {
     "elapsed": 6928,
     "status": "ok",
     "timestamp": 1698803943153,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "Zw6CH1mp0zR4"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import heatmap\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, \\\n",
    "mean_squared_error, precision_score, recall_score, accuracy_score, f1_score, \\\n",
    "ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# new libraries\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# This is used to overcome an issue with setting up tensorflow in M1/M1\n",
    "# Suspect tensorflow-macos not very fit with GPU, use CPU only with\n",
    "tf.config.set_visible_devices([], 'GPU')\n",
    "\n",
    "# Set random seeds for consistent outcomes\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5pga5rHChPu"
   },
   "source": [
    "### Plot History\n",
    "\n",
    "Since we will be plotting histories for all of our models, lets create a function to do it quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.226208Z",
     "start_time": "2023-02-08T02:15:00.220222Z"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1698803943153,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "UbrKqMv0_28Q"
   },
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "  \"\"\"Takes a keras model learning history and plots each metric\"\"\"\n",
    "\n",
    "  metrics = history.history.keys()\n",
    "\n",
    "  for metric in metrics:\n",
    "      if not 'val' in metric:\n",
    "        plt.plot(history.history[f'{metric}'], label=f'{metric}')\n",
    "        if f'val_{metric}' in metrics:\n",
    "          plt.plot(history.history[f'val_{metric}'], label=f'val_{metric}')\n",
    "        plt.legend()\n",
    "        plt.title(f'{metric}')\n",
    "        plt.show()\n",
    "\n",
    "def eval_regression(true, pred, name='Model'):\n",
    "    \"\"\"Evaluates true and predicted values from a regression model.\n",
    "    Outputs a dataframe of metrics\"\"\"\n",
    "    scores = pd.DataFrame()\n",
    "    scores['Model Name'] = [name]\n",
    "    scores['RMSE'] = [np.sqrt(mean_squared_error(true, pred))]\n",
    "    scores['MAE'] = [mean_absolute_error(true, pred)]\n",
    "    scores['R2'] = [r2_score(true, pred)]\n",
    "    scores.set_index('Model Name', inplace=True)\n",
    "\n",
    "    return scores\n",
    "\n",
    "def eval_classification(true, pred, name, labels=None):\n",
    "    \"\"\"shows classification_report and confusion matrix\n",
    "    for classification model predictions.  Outputs a dataframe of metrics\"\"\"\n",
    "\n",
    "    print(name, '\\n')\n",
    "    print(classification_report(true, pred, target_names=labels))\n",
    "    ConfusionMatrixDisplay.from_predictions(true, pred, display_labels=labels, )\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    scores = pd.DataFrame()\n",
    "    scores['Model Name'] = [name]\n",
    "    scores['Precision'] = [precision_score(true, pred)]\n",
    "    scores['Recall'] = [recall_score(true, pred)]\n",
    "    scores['F1 Score'] = [f1_score(true, pred)]\n",
    "    scores['Accuracy'] = [accuracy_score(true, pred)]\n",
    "    scores.set_index('Model Name', inplace=True)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAUUTWm93ojP"
   },
   "source": [
    "# Data\n",
    "\n",
    "We will be working with 2 different datasets in this project, 1 is a regression dataset and the other is a classification dataset.  This way you can practice doing both using deep learning.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "These datasets are very small for deep learning.  Deep learning models usually work best with very large datasets with at least 10,000 or more samples.  They work best on even larger datasets than that.  But, for demonstration we will use these smaller datasets.\n",
    "\n",
    "## Regression\n",
    "This is a dataset of housing prices in Boston from 1978.  Each row is a house and the dataset includes several features regarding each house.  Our target today will be the price of the home.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.312062Z",
     "start_time": "2023-02-08T02:15:00.227205Z"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698803943153,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "8_PM7Bt81FKh"
   },
   "outputs": [],
   "source": [
    "regression_df = pd.read_csv('Data/Boston_Housing_from_Sklearn.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1YPAPvdG6Sqy"
   },
   "source": [
    "# Regression\n",
    "\n",
    "Let's start with modeling the regression dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.324011Z",
     "start_time": "2023-02-08T02:15:00.314019Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1698803943369,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "3STtBugN3fp1",
    "outputId": "a8fdf0a0-c92d-42b5-9931-07089286b0ae"
   },
   "outputs": [],
   "source": [
    "regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.334424Z",
     "start_time": "2023-02-08T02:15:00.325015Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1698803943369,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "4sJoxV1ZJKBd",
    "outputId": "ca6b1cac-9d39-4a4f-b683-d4c2bcfe3fe9"
   },
   "outputs": [],
   "source": [
    "regression_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.341921Z",
     "start_time": "2023-02-08T02:15:00.336419Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1698803943369,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "uvcvdJUZ6YKX",
    "outputId": "c33ec5e8-9fdb-479c-d23a-b17558802b91"
   },
   "outputs": [],
   "source": [
    "regression_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.368107Z",
     "start_time": "2023-02-08T02:15:00.342920Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1698803943370,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "IrxmHTaU6s3N",
    "outputId": "0429c421-e5cb-4196-9317-11279e5b8668"
   },
   "outputs": [],
   "source": [
    "regression_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.377085Z",
     "start_time": "2023-02-08T02:15:00.370103Z"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1698803943370,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "rU0zM_dk6xDd"
   },
   "outputs": [],
   "source": [
    "# Define X and Y and complete the train test split\n",
    "X = regression_df.drop(columns = 'PRICE')\n",
    "y = regression_df['PRICE']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqS765vN8Xti"
   },
   "source": [
    "## Scaling\n",
    "\n",
    "### Important Notes\n",
    "- Always scale your data for deep learning.  \n",
    "- Otherwise you get a problem call 'Exploding Weights'.  \n",
    "- Some weights will be updated much faster than others because the inputs are at larger scales.  \n",
    "- This tends to hurt learning as data on smaller scales does not update as fast and doesn't get to contribute as much to the decision making process.  \n",
    "- By scaling we put all features on the same footing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:15:00.384069Z",
     "start_time": "2023-02-08T02:15:00.377085Z"
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "ok",
     "timestamp": 1698803943582,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "bvCCtAhQ7gGe"
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_proc = scaler.transform(X_train)\n",
    "X_test_proc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BzX4RBcu8TFx"
   },
   "source": [
    "## First Simple Model\n",
    "\n",
    "We always want to start simple, as deep learning models can get very complex fast and more complex models take more time to train and are more prone to overfitting.  A well performing simple model is better than a well performing complex model.\n",
    "\n",
    "## Input layer\n",
    "The first layer we will define is not technically the input layer.  We will define the first hidden layer with a special argument that tells Keras how to create a input layer:\n",
    "\n",
    "`input_dim=`\n",
    "\n",
    "Input layers can also be defined manually using tensorflow.keras.layers.InputLayer\n",
    "\n",
    "## Activation function\n",
    "\n",
    "For the single hidden layer we will try just 3 nodes and use a ReLU activation.  ReLUs tend to perform well for hidden layers.\n",
    "\n",
    "## Output Layer\n",
    "\n",
    "For the output layer (last layer) we just use one node because we only want the output of the model to be one number.  We will use a linear activation function.  This will simply output the value from the weights and bias in the node with no change.  The output will be a continuous number, a float.  This will make our model a regression model.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "glnm6hhh4M6u"
   },
   "source": [
    "# Note:\n",
    "### The first layer you define will NOT be the input layer!  Keras will create an input layer on its own, implicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:23:47.149108Z",
     "start_time": "2023-02-08T02:23:47.117114Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 191,
     "status": "ok",
     "timestamp": 1698803943771,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "AnjwY1dz7vcG",
    "outputId": "702a01f0-8afb-4f6d-e791-adc74722749a"
   },
   "outputs": [],
   "source": [
    "# Set Random Seeds\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Instantiate your sequential model\n",
    "\n",
    "# Add first hidden layer with 3 neurons THIS IS NOT THE INPUT LAYER!\n",
    "# Tell Keras how to construct the input layer shape using input_dim\n",
    "\n",
    "\n",
    "\n",
    "# Add output layer with 1 node\n",
    "\n",
    "\n",
    "# Check summary of network\n",
    "\n",
    "# Compile your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wAFuCDGOBzo"
   },
   "source": [
    "## Compiling\n",
    "\n",
    "Compiling the model puts all the pieces together to make it ready to train.  \n",
    "\n",
    "For this step, we need to specify a few other hyperparameters:\n",
    "\n",
    "* **Optimizer:** An Adam optimizer is a favorite and often performs well, it's a good place to start.\n",
    "  - Other optimizers : Gradient Descent, Stochastic Gradient Descent, Adagrad, RMSProp\n",
    "* **Loss Function:** 'mse' or mean squared error.  This is the number our model will try to reduce in each epoch.  Since this is a regression model we want our model to minimize the mean squared error.  A loss function ALWAYS needs to be a measurement of the total error that the model can REDUCE.  R^2 won't work because higher is better. We don't want the model to reduce R^2!\n",
    "* **Metrics:** 'mae' or mean absolute error.  We can provide a list of any appropriate metrics we want the model to keep track at each epoch.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:23:47.508163Z",
     "start_time": "2023-02-08T02:23:47.499157Z"
    },
    "executionInfo": {
     "elapsed": 165,
     "status": "ok",
     "timestamp": 1698803943935,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "AwAGvWCZN1WC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBvS_wkr_hEh"
   },
   "source": [
    "# Training (AKA fitting)\n",
    "\n",
    "Let's try training our model for 100 few epochs.  Sometimes that is enough, and it will give us an idea whether our model is learning anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:23:54.798328Z",
     "start_time": "2023-02-08T02:23:48.643134Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22461,
     "status": "ok",
     "timestamp": 1698803966394,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "81VFx1n1-TS7",
    "outputId": "38986443-be8d-41c0-8a54-27c0bd8fe38b"
   },
   "outputs": [],
   "source": [
    "# Fit your model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:23:55.237007Z",
     "start_time": "2023-02-08T02:23:54.799327Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1698803967207,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "q8Kox9hOOq7w",
    "outputId": "5b8cc291-1371-4b95-a2a1-67dff8477e19"
   },
   "outputs": [],
   "source": [
    "# Apply the custom function plot_history() to see how your model is doing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Ic8eFsL_x2m"
   },
   "source": [
    "## Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-08T02:24:13.846087Z",
     "start_time": "2023-02-08T02:24:13.638158Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1698803967448,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "33J5dOt3A8ZO",
    "outputId": "53d33b0a-4c41-470d-e0e1-b3c9584b0f66"
   },
   "outputs": [],
   "source": [
    "# Make predictions and evaluate your model\n",
    "train_preds = model.predict(X_train)\n",
    "test_preds = model.predict(X_test)\n",
    "\n",
    "train_scores = eval_regression(y_train, train_preds, name='base_reg_train')\n",
    "test_scores = eval_regression(y_test, test_preds, name='base_reg_test')\n",
    "\n",
    "reg_scores = pd.concat([train_scores, test_scores])\n",
    "reg_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TvQ16n8x7RWb"
   },
   "source": [
    "# <center> Temperature Check: </center>\n",
    "## On a scale of 0 - 5, how confident do you feel in coding neural networks?\n",
    "\n",
    "0. What is a neural net?\n",
    "1. I know what a neural net is, but I don't know how to even start coding one.\n",
    "2. I kinda get how the code flows, but need help from someone else to create my own.\n",
    "3. I understand the general idea, and could code a neural net in Keras if I had an example in front of me.\n",
    "4. I feel confident in coding a neural network with some reference materials.\n",
    "5. Move over, Josh.  I can finish this code-along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWaTq6c7FHlr"
   },
   "source": [
    "\n",
    "# Classification Models in Keras\n",
    "\n",
    "Classification models are similar, except that we need to adjust:\n",
    "* The final activation of the output layer, and\n",
    "* The loss function and metrics in the compile step.\n",
    "\n",
    "We will also need to do some processing of the predictions after training to make them integers instead of floats.\n",
    "\n",
    "### Remember:\n",
    "MAE, MSE, RMSE, and R2 are regression metrics,\n",
    "\n",
    "accuracy, recall, precision, and F1-Score are classification metrics.\n",
    "\n",
    "## Classification Dataset\n",
    "The classification dataset describes diabetes rates among Pima Indians.  Each row is a person and this dataset includes features regarding health related measurements.  The target is binary and represents whether or not a person will be diagnosed with diabetes.  This is another old dataset first presented in 1988.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1698803967448,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "CN1zHoGcGeFN",
    "outputId": "f0c37e65-f3e9-49fb-c46b-c42d66ef7117"
   },
   "outputs": [],
   "source": [
    "classification_df = pd.read_csv('https://raw.githubusercontent.com/ninja-josh/image-storage/main/diabetes.csv')\n",
    "classification_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1698803967448,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "isTaHNFpGjQH",
    "outputId": "f8373e6d-e9c3-40d4-d790-f71c23b701f9"
   },
   "outputs": [],
   "source": [
    "classification_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698803967448,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "HtZv-V73Gmjv",
    "outputId": "0cf5fa9f-33cc-47d1-b828-702de2a6f890"
   },
   "outputs": [],
   "source": [
    "classification_df.duplicated().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 244,
     "status": "ok",
     "timestamp": 1698803967688,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "sdF3qT-9Gp_s",
    "outputId": "c2110d77-0c19-4268-b285-32c2640cedd0"
   },
   "outputs": [],
   "source": [
    "classification_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l8cjiy3BGvLa"
   },
   "source": [
    "### Important Note:\n",
    "We see minimums for Glucose, BloodPression, SkinThickness, Insulin, and BMI of 0s.  Those are impossible for humans, so lets drop those rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1698803967689,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "TwzoeFVWG6Dd",
    "outputId": "1c35a985-cea6-441a-b58a-b8fdcab78117"
   },
   "outputs": [],
   "source": [
    "no_glucose = classification_df['Glucose'] == 0\n",
    "no_blood = classification_df['BloodPressure'] == 0\n",
    "no_skin = classification_df['SkinThickness'] == 0\n",
    "no_insulin = classification_df['Insulin'] == 0\n",
    "no_bmi = classification_df['BMI'] == 0\n",
    "\n",
    "#class_df_clean excludes rows that have no values == 0 in the above columns\n",
    "class_df_clean = classification_df[~(no_glucose |\n",
    "                                     no_blood |\n",
    "                                     no_skin |\n",
    "                                     no_insulin |\n",
    "                                     no_bmi)]\n",
    "class_df_clean.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQqWsTbaM5It"
   },
   "source": [
    "We lost a lot of data, going from 768 samples to 392 samples.  In the future we might impute this data using means, medians, or other imputation strategies.  For this exercise we won't focus on that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H3mqMU6SJZlO"
   },
   "source": [
    "### Important Note:\n",
    "\n",
    "This stratify parameter makes a split so that the proportion of values in the sample produced will be the same as the proportion of values provided to parameter stratify.\n",
    "\n",
    "For example, if variable y is a binary categorical variable with values 0 and 1 and there are 25% of zeros and 75% of ones, stratify=y will make sure that your random split has 25% of 0's and 75% of 1's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1698803967689,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "JjREwrWgGPtP"
   },
   "outputs": [],
   "source": [
    "# Define X and y and train test split\n",
    "X = class_df_clean.drop(columns = 'Outcome')\n",
    "y = class_df_clean['Outcome']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1698803967689,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "bE0MPxsBJZlP",
    "outputId": "243735cd-5b06-403c-b4dc-6ad4292d3b75"
   },
   "outputs": [],
   "source": [
    "# Proportions of 0 and 1 in the dataset\n",
    "y.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1698803967689,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "sO-5i_X7JZlP",
    "outputId": "ca91fca6-df64-4fb6-9d3a-4b1c9211e606"
   },
   "outputs": [],
   "source": [
    "# Proportions of 0 and 1 in the train dataset\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1698803967689,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "ccjfu2pdJZlP",
    "outputId": "41da206e-4f3e-4220-d585-70e2b1dee4ff"
   },
   "outputs": [],
   "source": [
    "# Proportions of 0 and 1 in the test dataset\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1698803967689,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "EKPiCOByPOfF"
   },
   "outputs": [],
   "source": [
    "# Scale the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TWU179nQIdt"
   },
   "source": [
    "## Build the Classification Model\n",
    "\n",
    "We need to do a few things differently here because this is a binary classification:\n",
    "\n",
    "1. The activation of our final layer needs to be 'sigmoid'.  \n",
    "\n",
    "\n",
    "(If this were multiclass classification, we would set the final activation as 'softmax' and the number of output nodes would be the number of classes in our y_train.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 204,
     "status": "ok",
     "timestamp": 1698803967889,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "lAwy3AXrPjwH",
    "outputId": "c89302f6-b241-4c46-878c-100361bd0a5a"
   },
   "outputs": [],
   "source": [
    "# Set Random Seeds\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Build your model\n",
    "\n",
    "\n",
    "\n",
    "# One output node with 'sigmoid' activation\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4nrwLXyKPpO1"
   },
   "source": [
    "## More Changes for Classification:\n",
    "\n",
    "1.  We need to change our loss to 'binary_crossentropy', or 'bce'.  If this were multiclass we would use 'categorical_crossentrobpy'.\n",
    "\n",
    "2. Our metrics should be classification metrics.  We will use accuracy and import recall and precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1698803967889,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "GOe9CMP2PtDT"
   },
   "outputs": [],
   "source": [
    "from keras.metrics import Precision, Recall\n",
    "\n",
    "# Compile your model with loss='bce, set metrics = ['acc', Precision(), Recall()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 42183,
     "status": "ok",
     "timestamp": 1698804010065,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "vScTvfoKOVLO",
    "outputId": "8106018a-5a36-4175-c6bb-c6924f9730cd"
   },
   "outputs": [],
   "source": [
    "# fit your model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1698804010065,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "OTmswQ-tJZlX",
    "outputId": "d4eb9d6d-e4cf-4250-bf54-d5c23e16fc37"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 645,
     "status": "ok",
     "timestamp": 1698804010706,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "qKLxgYDcP0_H",
    "outputId": "e2de98d9-02bc-478f-b52c-8f1bef07e28e"
   },
   "outputs": [],
   "source": [
    "# See how your model is doing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LD18RKjYTFXP"
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "Keras models always output floats, not integers.  In this case the final sigmoid activation function will return a number between 0 and 1.  If the number is closer to 1, the model predicts the sample is more likely to be class 1.  If it is closer to 2, the sample is predicted to be more likely to be class 0.  \n",
    "\n",
    "This is similar to the output of .predict_proba() with Scikit-Learn models.\n",
    "\n",
    "### Converting Floats to Ints\n",
    "\n",
    "In order to use Scikit-Learn metrics functions, the float outputs of the model need to be converted to ints.  We don't want to just use `int(pred)` or `pred.astype(int)` because that will just drop the decimal and all our predictions would be 0s.  \n",
    "\n",
    "Instead we want to **round** the predictions to the nearest integer. To round all of the numbers in an array we can use the NumPy function, `np.rint()` which is short for 'round to integer'.  \n",
    "\n",
    "[Numpy Reference for np.rint()](https://numpy.org/doc/stable/reference/generated/numpy.rint.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1698804010945,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "HttQV2phV-Va",
    "outputId": "f17ae13d-e97f-4e3e-e1d2-c065ae8c5b3b"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1698804010945,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "u1CSEpv4YXV7",
    "outputId": "a39a681f-97b1-4569-eea3-6a90c76bb333"
   },
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# round predictions to integers instead of floats using np.rint()\n",
    "\n",
    "\n",
    "\n",
    "# the following code should show whole number predictions, 1.0 or 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 691,
     "status": "ok",
     "timestamp": 1698804011629,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "sov8ZJUHP-Bf",
    "outputId": "3b3ca2ec-3b96-4c69-8f47-3dff45aea337"
   },
   "outputs": [],
   "source": [
    "# Define labels for the confusion matrix\n",
    "labels = ['No Diabetes', 'Diabetes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1698804011630,
     "user": {
      "displayName": "Yvon Bilodeau",
      "userId": "10142856831792134633"
     },
     "user_tz": 420
    },
    "id": "vFvHcmtIsSCy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "1AMkk4AkOwuh0L19EdXpLJHJaeZXCP6kQ",
     "timestamp": 1654554871276
    },
    {
     "file_id": "1HZQ_jeFRQsrlNGjvh_ru52Q-1DhIahua",
     "timestamp": 1636586978598
    }
   ],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "243.829px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
